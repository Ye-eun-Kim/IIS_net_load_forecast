{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import MeanAbsolutePercentageError as MAPE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, sys, os\n",
    "import Dataset_Class as DC\n",
    "\n",
    "\n",
    "\n",
    "# USE_CUDA = torch.cuda.is_available()\n",
    "# DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "DEVICE = 'cpu'\n",
    "RANDOM_SEED = 2023\n",
    "EPOCHS = 50000\n",
    "LEARNING_RATE = 0.000001\n",
    "BATCH_SIZE = 16\n",
    "# BATCH_SIZE = int(sys.argv[2])\n",
    "\n",
    "# patience 3, batch_size 16, learning rate 0.000001, model(50-64-256-64-24) shows the best result\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, col_len, **model_config):\n",
    "        super(Net, self).__init__()\n",
    "        self.model_type = model_config['case']\n",
    "        if model_config['case'] == 1:\n",
    "            self.hidd_dim = 512\n",
    "            self.hidden_dim = 75\n",
    "        elif model_config['case'] == 2:\n",
    "            self.hidd_dim = 1500\n",
    "            self.hidden_dim = 5000\n",
    "            self.hidden_dimm = 300\n",
    "        elif model_config['case'] == 3:\n",
    "            self.hidd_dim = 500\n",
    "            self.hidden_dim = 75  #good\n",
    "        elif model_config['case'] == 4:\n",
    "            self.hidd_dim = 250\n",
    "            self.hidden_dim = 75\n",
    "            \n",
    "        self.fc1 = nn.Linear(col_len, self.hidd_dim)\n",
    "        self.fc2 = nn.Linear(self.hidd_dim, self.hidden_dim)\n",
    "        # self.fc3 = nn.Linear(self.hidden_dim, 24)\n",
    "        self.fc3 = nn.Linear(self.hidden_dim, self.hidden_dimm)\n",
    "        self.fc4 = nn.Linear(self.hidden_dimm, 24)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        # output = self.fc3(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.fc4(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "# load the data and split into X and Y\n",
    "def load_data(drop_features, building):\n",
    "    if building == 'RISE':\n",
    "        X_pv = pd.read_csv('./processed_data/pv/X_pv_231days_RISE.csv', index_col=0)\n",
    "        Y_pv = pd.read_csv('./processed_data/pv/Y_pv_231days_RISE.csv', index_col=0)\n",
    "    elif building == 'DORM':\n",
    "        X_pv = pd.read_csv('./processed_data/pv/X_pv_231days_DORM.csv', index_col=0)\n",
    "        Y_pv = pd.read_csv('./processed_data/pv/Y_pv_231days_DORM.csv', index_col=0)\n",
    "\n",
    "    label_interval = get_label_interval(X_pv)\n",
    "    if drop_features != 'No_drop':\n",
    "        X = X_pv.drop(columns = drop_features)\n",
    "    else:\n",
    "        X = X_pv\n",
    "        \n",
    "    Y = Y_pv.iloc[:,0:24]\n",
    "    col = X.columns\n",
    "    col_len = len(col)\n",
    "    X = torch.FloatTensor(X.values)\n",
    "    Y = torch.FloatTensor(Y.values)\n",
    "    return X, Y, col, col_len, label_interval\n",
    "\n",
    "\n",
    "# split data into mini_train, valid, train, test\n",
    "def split_data(X, Y, batch_size, data_len, train_pie, mini_train_pie):\n",
    "    train_size = int(data_len * train_pie)\n",
    "    mini_train_size = int(train_size * mini_train_pie)\n",
    "    \n",
    "    train_data = DC.CustomDataset(X[:train_size], Y[:train_size])\n",
    "    test_data = DC.CustomDataset(X[train_size:], Y[train_size:])\n",
    "    mini_train_data = DC.CustomDataset(X[:mini_train_size], Y[:mini_train_size])\n",
    "    valid_data = DC.CustomDataset(X[mini_train_size:train_size], Y[mini_train_size:train_size])\n",
    "    mini_train_dataloader = DataLoader(mini_train_data, batch_size = batch_size, shuffle = True)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size = len(valid_data), shuffle = False)\n",
    "    train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size = len(test_data), shuffle = False)\n",
    "    \n",
    "    return mini_train_dataloader, valid_dataloader, train_dataloader, test_dataloader, mini_train_size, train_size\n",
    "\n",
    "\n",
    "# get the number of days of each month as label_interval list\n",
    "def get_label_interval(X):\n",
    "    label_interval = []\n",
    "    for i in range(1, 13):\n",
    "        cnt = 0\n",
    "        for idx in X.index:\n",
    "            if '21{0:0>2}'.format(i) in str(idx):\n",
    "                cnt+=1\n",
    "        label_interval.append(cnt)\n",
    "    return label_interval\n",
    "        \n",
    "        \n",
    "\n",
    "# create folder if not exist\n",
    "def create_folder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "\n",
    "# plot daily feature graphs\n",
    "def plot_daily_feature(X, label_interval, col_list, fig_size, font_size, mini_train_point, valid_point, pre_save_path):\n",
    "    unit=''\n",
    "    pv_col_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
    "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "    for idx, col in enumerate(col_list):\n",
    "        if col in pv_col_list:\n",
    "            if col == '0':\n",
    "                data = torch.sum(X[:,idx:idx+24], axis=1).detach().numpy().reshape(-1)\n",
    "                col = 'PV Generation'\n",
    "                unit = 'kWh'\n",
    "            else:\n",
    "                continue\n",
    "        elif 'DS' in col:\n",
    "            # column: duration of sunshine\n",
    "            data = X[:,idx]\n",
    "            unit = 'hr'\n",
    "        elif 'SL' in col:\n",
    "            # column: sunlight\n",
    "            data = X[:,idx]\n",
    "            unit = 'hr'\n",
    "        elif 'SR' in col:\n",
    "            # column: solar radiation\n",
    "            data = X[:,idx]\n",
    "            unit = 'MJ/m2'\n",
    "        elif 'TM_15' in col:\n",
    "            #column: temperature of 15h on next day\n",
    "            data = X[:,idx]\n",
    "            unit = '℃'\n",
    "        elif 'WS_15' in col:\n",
    "            # column: wind speed of 15h on next day\n",
    "            data = X[:,idx]\n",
    "            unit = 'm/s'\n",
    "        elif 'SK_15' in col:\n",
    "            # column: state of sky of 15h on next day\n",
    "            data = X[:,idx]\n",
    "            col = 'SK_15'\n",
    "            unit = '(1: clear, 3: partly cloudy, 4: cloudy)' \n",
    "        elif 'PP_15' in col:\n",
    "            # column: probability of precipitation of 15h on next day\n",
    "            data = X[:,idx]\n",
    "            unit = '%'\n",
    "        elif 'PR_15' in col:\n",
    "            #column: precipitation of 15h on next day\n",
    "            data = X[:,idx]\n",
    "            unit = 'mm'\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Create figure and plot the data\n",
    "        fig = plt.figure(figsize=fig_size)\n",
    "        ax = plt.axes()\n",
    "        ax.plot(data)\n",
    "\n",
    "        plt.title(col+\" Fluctuation in 2021\", fontsize = font_size)\n",
    "        plt.xlabel('Month', fontsize = font_size)\n",
    "        plt.ylabel(col+' ('+unit+')', fontsize = font_size)\n",
    "\n",
    "        # Set the x-tick positions and labels\n",
    "        x_ticks = []\n",
    "        x_labels = []\n",
    "        for i, interval in enumerate(label_interval):\n",
    "            start = sum(label_interval[:i])\n",
    "            x_ticks.append(start)\n",
    "            x_labels.append(f'{i+1}')\n",
    "\n",
    "        plt.axvline(x = mini_train_point, c='r')\n",
    "        plt.axvline(x = valid_point, c='r')\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels(x_labels)\n",
    "        \n",
    "        # save the figure\n",
    "        plt.savefig(pre_save_path+col+'.png')\n",
    "\n",
    "\n",
    "def plot_loss(mini_train_loss_arr, val_loss_arr, range_start, best_val_epoch, fig_size, title, font_size, save_path):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.title(title, fontsize = font_size)\n",
    "    # plt.xlabel('Epoch', fontsize = font_size)\n",
    "    plt.ylabel('Loss(MSE)', fontsize = font_size)\n",
    "    plt.plot(mini_train_loss_arr, c = 'blue', label = 'Train')\n",
    "    plt.plot(val_loss_arr, c = 'orange', label = 'Validation')\n",
    "    plt.legend(loc='upper right', fontsize = font_size)\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.title(title+' from Epoch '+str(range_start)+' every epoch 200', fontsize = font_size)\n",
    "    # plt.xlabel('Epoch', fontsize = font_size)\n",
    "    plt.ylabel('Loss(MSE)', fontsize = font_size)\n",
    "    plt.plot(np.arange(range_start, best_val_epoch, 200), mini_train_loss_arr[range_start:best_val_epoch:200], c = 'blue', label = 'Train')\n",
    "    plt.plot(np.arange(range_start, best_val_epoch, 200), val_loss_arr[range_start:best_val_epoch:200], c = 'orange', label = 'Validation')\n",
    "    plt.legend(loc='upper right', fontsize = font_size)\n",
    "\n",
    "    plt.subplot(223)\n",
    "    plt.title(title+' from Epoch '+str(range_start), fontsize = font_size)\n",
    "    plt.xlabel('Epoch', fontsize = font_size)\n",
    "    plt.ylabel('Loss(MSE)', fontsize = font_size)\n",
    "    plt.plot(mini_train_loss_arr[range_start:], c = 'blue', label = 'Train')\n",
    "    plt.legend(loc='upper right', fontsize = font_size)\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.title(title+' from Epoch '+str(range_start), fontsize = font_size)\n",
    "    plt.xlabel('Epoch', fontsize = font_size)\n",
    "    plt.ylabel('Loss(MSE)', fontsize = font_size)\n",
    "    plt.plot(val_loss_arr[range_start:], c = 'orange', label = 'Validation')\n",
    "    plt.legend(loc='upper right', fontsize = font_size)\n",
    "\n",
    "    plt.subplots_adjust(left=0.125, bottom=0.1,  right=0.9, top=0.9, wspace=0.35, hspace=0.35)\n",
    "    \n",
    "    # save the figure\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    \n",
    "def plot(i, length, output, Y, fig_size, title, font_size, save_path):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    plt.title(title, fontsize = font_size)\n",
    "    plt.xlabel('Time (h)', fontsize = font_size)\n",
    "    plt.ylabel('PV', fontsize = font_size)\n",
    "    plt.plot(Y.detach().numpy()[i:i+length,:].reshape(-1), c='blue', label = 'Actual data')\n",
    "    plt.plot(output.detach().numpy()[i:i+length,:].reshape(-1), c='red', label = 'forecast data')\n",
    "    plt.legend(loc='lower right', fontsize = 13)\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "     \n",
    "def train(model, train_dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    for (x, y) in train_dataloader:\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        \n",
    "        output = model(x)\n",
    "        train_loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += train_loss\n",
    "    \n",
    "    return (loss_sum/len(train_dataloader.dataset)/24).item() # loss of each epoch\n",
    "\n",
    "\n",
    "def evaluate(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in valid_dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "                \n",
    "            output = model(x)\n",
    "            \n",
    "        return output, y\n",
    "\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "model_case = 2\n",
    "building = 'RISE'\n",
    "drop_features = 'No_drop'\n",
    "mae = nn.L1Loss()\n",
    "mape = MAPE()\n",
    "\n",
    "\n",
    "\n",
    "# data loading\n",
    "# X: 210104-211229, Y: 210105-211230 / 231*50\n",
    "X, Y, col_list, col_len, label_interval = load_data(drop_features, building)\n",
    "dataset = DC.CustomDataset(X, Y)\n",
    "data_len = len(dataset)\n",
    "mini_train_dataloader, valid_dataloader, train_dataloader, test_dataloader, mini_train_size, train_size =  split_data(X, Y, BATCH_SIZE, data_len, 0.8, 0.8)\n",
    "# 147개   210104 ~ 210819\n",
    "# 37개    210820 ~ 211015\n",
    "# 184개   210104 ~ 211015\n",
    "# 47개    211018 ~ 211229\n",
    "\n",
    "\n",
    "\n",
    "# data plotting\n",
    "dir = './experiment_outputs/pv_forecast/'\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%m%d_%H%M\")\n",
    "\n",
    "file_name = f'{building}_{timestamp}_{model_case}_{drop_features}_{EPOCHS}_{LEARNING_RATE}_{BATCH_SIZE}'\n",
    "_path = dir+\"plots/daily_pv_features/\"+file_name\n",
    "create_folder(_path)\n",
    "# plot_daily_feature(X, label_interval, col_list, (10,2.5), 8, mini_train_size-1, train_size-1, _path+'/')\n",
    "\n",
    "\n",
    "# model setting\n",
    "model_config = {'case': model_case}\n",
    "model = Net(col_len, **model_config).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.MSELoss(reduction='sum').to(DEVICE)\n",
    "criterion2 = nn.MSELoss(reduction = 'mean').to(DEVICE)\n",
    "\n",
    "\n",
    "# file to save the results\n",
    "f = open(dir+f\"results/{file_name}.txt\", 'w')\n",
    "\n",
    "\n",
    "# model training and validation\n",
    "mini_train_loss_arr = []\n",
    "val_loss_arr = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_epoch = 0\n",
    "patience = 0\n",
    "\n",
    "\n",
    "\n",
    "# load state_dict from model.pt file\n",
    "model.load_state_dict(torch.load('./experiment_outputs/pv_forecast/models/RISE_0328_1504_2_No_drop_50000_1e-06_16.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output, test_y = evaluate(model, test_dataloader)\n",
    "test_output = torch.where(test_output > 0, test_output, 0)\n",
    "test_output[:,0:6] = 0\n",
    "test_output[:, 21:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(697.8568)\n",
      "tensor(1.4880)\n",
      "tensor(19.7254)\n"
     ]
    }
   ],
   "source": [
    "# 1517\n",
    "mape_sum = 0\n",
    "mean_test_y = 0\n",
    "cnt=0\n",
    "for i, tensor in enumerate(test_y):\n",
    "    for j, value in enumerate(tensor):\n",
    "        if value != 0:\n",
    "            output = test_output[i][j]\n",
    "            mape_sum += (abs(output - value) / value)\n",
    "            # print(i, j, output, value, abs(output - value) / value)\n",
    "            cnt += 1\n",
    "            mean_test_y+=value\n",
    "\n",
    "mean_test_y /= cnt\n",
    "\n",
    "print(mape_sum)\n",
    "print(mape_sum/cnt)\n",
    "print(mean_test_y)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58.5090)\n",
      "tensor(0.2760)\n"
     ]
    }
   ],
   "source": [
    "# 1517, 평균보다 클 때만\n",
    "\n",
    "mape_sum = 0\n",
    "cnt=0\n",
    "for i, tensor in enumerate(test_y):\n",
    "    for j, value in enumerate(tensor):\n",
    "        if value != 0 and value > mean_test_y:\n",
    "            output = test_output[i][j]\n",
    "            mape_sum += (abs(output - value) / value)\n",
    "            # print(i, j, output, value, abs(output - value) / value)\n",
    "            cnt += 1\n",
    "\n",
    "print(mape_sum)\n",
    "print(mape_sum/cnt)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(633.5475)\n",
      "tensor(1.3508)\n",
      "tensor(19.7254)\n"
     ]
    }
   ],
   "source": [
    "# 1504\n",
    "\n",
    "mape_sum = 0\n",
    "mean_test_y = 0\n",
    "cnt=0\n",
    "for i, tensor in enumerate(test_y):\n",
    "    for j, value in enumerate(tensor):\n",
    "        if value != 0:\n",
    "            output = test_output[i][j]\n",
    "            mape_sum += (abs(output - value) / value)\n",
    "            # print(i, j, output, value, abs(output - value) / value)\n",
    "            cnt += 1\n",
    "            mean_test_y+=value\n",
    "\n",
    "mean_test_y /= cnt\n",
    "\n",
    "print(mape_sum)\n",
    "print(mape_sum/cnt)\n",
    "print(mean_test_y)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58.0576)\n",
      "tensor(0.2739)\n"
     ]
    }
   ],
   "source": [
    "# 1504, 평균보다 클 때만\n",
    "\n",
    "mape_sum = 0\n",
    "cnt=0\n",
    "for i, tensor in enumerate(test_y):\n",
    "    for j, value in enumerate(tensor):\n",
    "        if value != 0 and value > mean_test_y:\n",
    "            output = test_output[i][j]\n",
    "            mape_sum += (abs(output - value) / value)\n",
    "            # print(i, j, output, value, abs(output - value) / value)\n",
    "            cnt += 1\n",
    "\n",
    "print(mape_sum)\n",
    "print(mape_sum/cnt)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yekim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
